"""
Backend stable pour les agents IA avec WebSocket et int√©gration React optimis√©e
Version corrig√©e avec gestion robuste des connexions WebSocket
"""
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import ollama
import time
import logging
import json
import asyncio
from datetime import datetime
import uuid
import traceback

# Configuration des logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI(title="AI Agents API - Stable Enhanced", version="2.0.1")

# Configuration CORS s√©curis√©e
# Configuration CORS s√©curis√©e et √©largie
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "http://127.0.0.1:5173",
        "http://localhost:3000",
        "http://localhost:3001",
        "http://127.0.0.1:3000",
        "http://127.0.0.1:3001"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# Mod√®les Pydantic
class ChatRequest(BaseModel):
    agent_name: str
    message: str
    context: Optional[Dict] = None

class WorkflowRequest(BaseModel):
    user_input: str
    agent_names: Optional[List[str]] = None

class WebSocketWorkflowRequest(BaseModel):
    prompt: str
    selected_agents: List[str]
    session_id: str

class AgentResponse(BaseModel):
    agent: str
    response: str
    model: str
    execution_time: float
    timestamp: datetime

# Configuration des agents avec vos modelfiles
AGENT_CONFIGS = {
    "Mike": {
        "model": "agent-visionnaire",
        "role": "Team Leader / Visionnaire",
        "description": "Coordinateur de projet et d√©finition de vision",
        "color": "#FF6B6B",
        "emoji": "üéØ"
    },
    "Bob": {
        "model": "agent-architecte", 
        "role": "Architecte Logiciel",
        "description": "Expert en architecture technique",
        "color": "#FFEAA7",
        "emoji": "üèóÔ∏è"
    },
    "FrontEngineer": {
        "model": "agent-frontend-engineer",
        "role": "Ing√©nieur Frontend", 
        "description": "D√©veloppeur React/JavaScript",
        "color": "#4ECDC4",
        "emoji": "‚ö°"
    },
    "BackEngineer": {
        "model": "agent-backend-engineer",
        "role": "Ing√©nieur Backend",
        "description": "D√©veloppeur FastAPI/Python",
        "color": "#45B7D1", 
        "emoji": "üîß"
    },
    "UIDesigner": {
        "model": "agent-designer-ui-ux",
        "role": "Designer UI/UX",
        "description": "Expert en design d'interface",
        "color": "#96CEB4",
        "emoji": "üé®"
    },
    "SEOExpert": {
        "model": "agent-seo-content-expert",
        "role": "Expert SEO/Contenu",
        "description": "Sp√©cialiste SEO et contenu",
        "color": "#F8B500",
        "emoji": "üìù"
    },
    "DBMaster": {
        "model": "agent-database-specialist",
        "role": "Sp√©cialiste Base de Donn√©es", 
        "description": "Expert en bases de donn√©es",
        "color": "#A29BFE",
        "emoji": "üóÑÔ∏è"
    },
    "DevOpsGuy": {
        "model": "agent-deployer-devops",
        "role": "Expert DevOps",
        "description": "Sp√©cialiste d√©ploiement",
        "color": "#DDA0DD",
        "emoji": "üöÄ"
    },
    "TheCritique": {
        "model": "agent-critique",
        "role": "Critique Qualit√©",
        "description": "Expert en qualit√© et s√©curit√©",
        "color": "#FF7675", 
        "emoji": "üîç"
    },
    "TheOptimizer": {
        "model": "agent-optimiseur",
        "role": "Optimiseur de Code",
        "description": "Expert en optimisation",
        "color": "#6C5CE7",
        "emoji": "‚ö°"
    },
    "TranslatorBot": {
        "model": "agent-translator",
        "role": "Traducteur",
        "description": "Expert en traduction",
        "color": "#FD79A8",
        "emoji": "üåê"
    }
}

# Gestionnaire de connexions WebSocket
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.connection_lock = asyncio.Lock()
        self.heartbeat_tasks: Dict[str, asyncio.Task] = {}
        self.max_connections = 50
    
    async def connect(self, websocket: WebSocket, session_id: str):
        """Connexion s√©curis√©e avec v√©rifications"""
        # V√©rifier le nombre de connexions
        if len(self.active_connections) >= self.max_connections:
            await websocket.close(code=1008, reason="Trop de connexions actives")
            return False
        
        # V√©rifier si la session existe d√©j√†
        if session_id in self.active_connections:
            await websocket.close(code=1008, reason="Session d√©j√† active")
            return False
        
        await websocket.accept()
        
        async with self.connection_lock:
            self.active_connections[session_id] = websocket
            logger.info(f"[{session_id}] Nouvelle connexion - Total: {len(self.active_connections)}")
        
        # D√©marrer le heartbeat
        self.heartbeat_tasks[session_id] = asyncio.create_task(
            self._heartbeat_task(websocket, session_id)
        )
        
        return True
    
    async def disconnect(self, session_id: str):
        """D√©connexion propre"""
        async with self.connection_lock:
            if session_id in self.active_connections:
                del self.active_connections[session_id]
                logger.info(f"[{session_id}] Connexion ferm√©e - Total: {len(self.active_connections)}")
        
        # Arr√™ter le heartbeat
        if session_id in self.heartbeat_tasks:
            self.heartbeat_tasks[session_id].cancel()
            del self.heartbeat_tasks[session_id]
    
    async def send_personal_message(self, message: str, session_id: str):
        """Envoi de message s√©curis√©"""
        if session_id in self.active_connections:
            websocket = self.active_connections[session_id]
            try:
                await websocket.send_text(message)
                return True
            except Exception as e:
                logger.error(f"[{session_id}] Erreur envoi message: {e}")
                await self.disconnect(session_id)
                return False
        return False
    
    async def _heartbeat_task(self, websocket: WebSocket, session_id: str):
        """Heartbeat pour d√©tecter les connexions mortes"""
        try:
            while True:
                await asyncio.sleep(30)  # Heartbeat toutes les 30 secondes
                try:
                    await websocket.send_text(json.dumps({
                        "type": "heartbeat",
                        "timestamp": datetime.now().isoformat()
                    }))
                except Exception:
                    break
        except asyncio.CancelledError:
            pass
        except Exception as e:
            logger.error(f"[{session_id}] Erreur heartbeat: {e}")
        finally:
            await self.disconnect(session_id)

# Agent am√©lior√© avec gestion d'erreurs robuste
class EnhancedAgent:
    def __init__(self, name: str, config: dict):
        self.name = name
        self.model = config["model"]
        self.role = config["role"]
        self.description = config["description"]
        self.color = config["color"]
        self.emoji = config["emoji"]
        self._model_available = None
        self._last_check = 0
        
    def check_model_availability(self) -> bool:
        """V√©rifie si le mod√®le Ollama est disponible avec cache"""
        current_time = time.time()
        
        # Cache la v√©rification pendant 60 secondes
        if self._model_available is not None and (current_time - self._last_check) < 60:
            return self._model_available
        
        try:
            models = ollama.list()
            available_models = [model['name'] for model in models.get('models', [])]
            self._model_available = self.model in available_models
            self._last_check = current_time
            return self._model_available
        except Exception as e:
            logger.error(f"Erreur v√©rification mod√®le {self.model}: {e}")
            self._model_available = False
            return False
    
    def think(self, context: Dict[str, Any]) -> str:
        """R√©flexion contr√¥l√©e avec fallback"""
        if not self.check_model_availability():
            return f"‚ùå Mod√®le {self.model} non disponible. Installez-le avec: ollama pull {self.model}"
        
        prompt = f"En tant que {self.role}, donnez une r√©flexion courte sur cette situation."
        
        try:
            response = ollama.generate(
                model=self.model, 
                prompt=prompt,
                options={
                    "num_predict": 150,
                    "temperature": 0.6,
                    "stop": ["\n\n"],
                    "num_ctx": 2048
                }
            )
            return response['response'][:250]
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration {self.name}: {e}")
            return f"ü§ñ {self.name}: R√©flexion temporairement indisponible - {str(e)[:50]}..."
    
    async def act_async(self, user_input: str, context: Dict[str, Any], max_retries: int = 2) -> str:
        """Action asynchrone avec retry"""
        for attempt in range(max_retries + 1):
            try:
                if not self.check_model_availability():
                    return self._generate_fallback_response(user_input)
                
                # Prompt contextualis√© selon le r√¥le
                role_prompts = {
                    "Team Leader / Visionnaire": f"En tant que visionnaire, analysez cette demande et proposez une approche strat√©gique: {user_input}",
                    "Architecte Logiciel": f"En tant qu'architecte, concevez une solution technique pour: {user_input}",
                    "Ing√©nieur Frontend": f"En tant que d√©veloppeur frontend, proposez une solution React/JavaScript pour: {user_input}",
                    "Ing√©nieur Backend": f"En tant que d√©veloppeur backend, concevez une API FastAPI pour: {user_input}",
                    "Designer UI/UX": f"En tant que designer, proposez une interface utilisateur pour: {user_input}",
                    "Expert SEO/Contenu": f"En tant qu'expert SEO, optimisez le contenu pour: {user_input}",
                    "Sp√©cialiste Base de Donn√©es": f"En tant qu'expert BDD, concevez un sch√©ma pour: {user_input}",
                    "Expert DevOps": f"En tant qu'expert DevOps, proposez un d√©ploiement pour: {user_input}",
                    "Critique Qualit√©": f"En tant que critique, analysez les points d'am√©lioration pour: {user_input}",
                    "Optimiseur de Code": f"En tant qu'optimiseur, am√©liorez la performance de: {user_input}",
                    "Traducteur": f"En tant que traducteur, adaptez ce contenu: {user_input}"
                }
                
                prompt = role_prompts.get(self.role, f"R√©pondez √† cette demande: {user_input}")
                
                response = ollama.generate(
                    model=self.model, 
                    prompt=prompt,
                    options={
                        "num_predict": 300,
                        "temperature": 0.7,
                        "stop": ["---", "\n\n\n"],
                        "num_ctx": 4096
                    }
                )
                
                result = response['response'][:500]
                return f"{self.emoji} **{self.name}** ({self.role}):\n\n{result}"
                
            except Exception as e:
                if attempt == max_retries:
                    logger.error(f"Erreur action {self.name} apr√®s {max_retries} tentatives: {e}")
                    return self._generate_fallback_response(user_input)
                
                logger.warning(f"Tentative {attempt + 1} √©chou√©e pour {self.name}: {e}")
                await asyncio.sleep(1)
        
        return self._generate_fallback_response(user_input)
    
    def act(self, user_input: str, context: Dict[str, Any]) -> str:
        """Version synchrone pour compatibilit√©"""
        try:
            loop = asyncio.get_event_loop()
            return loop.run_until_complete(self.act_async(user_input, context))
        except RuntimeError:
            # Si pas de loop, utiliser la version synchrone
            return self._act_sync(user_input, context)
    
    def _act_sync(self, user_input: str, context: Dict[str, Any]) -> str:
        """Version synchrone de l'action"""
        if not self.check_model_availability():
            return self._generate_fallback_response(user_input)
        
        try:
            prompt = f"En tant que {self.role}, r√©pondez √†: {user_input}"
            response = ollama.generate(
                model=self.model, 
                prompt=prompt,
                options={
                    "num_predict": 300,
                    "temperature": 0.7,
                    "num_ctx": 4096
                }
            )
            result = response['response'][:500]
            return f"{self.emoji} **{self.name}** ({self.role}):\n\n{result}"
        except Exception as e:
            logger.error(f"Erreur action sync {self.name}: {e}")
            return self._generate_fallback_response(user_input)
    
    def _generate_fallback_response(self, user_input: str) -> str:
        """R√©ponse de fallback intelligente selon le r√¥le"""
        fallbacks = {
            "Team Leader / Visionnaire": f"üéØ Vision strat√©gique pour '{user_input[:30]}...': Approche collaborative recommand√©e avec analyse des besoins utilisateurs.",
            "Architecte Logiciel": f"üèóÔ∏è Architecture sugg√©r√©e: Microservices avec FastAPI backend, React frontend, base de donn√©es adapt√©e au cas d'usage.",
            "Ing√©nieur Frontend": f"‚ö° Solution frontend: Interface React avec composants r√©utilisables, √©tat g√©r√© par hooks, design responsive.",
            "Ing√©nieur Backend": f"üîß API backend: Endpoints FastAPI avec validation Pydantic, authentification JWT, documentation Swagger.",
            "Designer UI/UX": f"üé® Design interface: Layout moderne, palette coh√©rente, exp√©rience utilisateur intuitive avec animations fluides.",
            "Expert SEO/Contenu": f"üìù Optimisation SEO: Contenu structur√©, mots-cl√©s pertinents, balises meta optimis√©es pour le r√©f√©rencement.",
            "Sp√©cialiste Base de Donn√©es": f"üóÑÔ∏è Sch√©ma BDD: Tables normalis√©es, index optimis√©s, relations bien d√©finies selon les besoins.",
            "Expert DevOps": f"üöÄ D√©ploiement: Conteneurs Docker, CI/CD automatis√©, monitoring et scalabilit√© assur√©s.",
            "Critique Qualit√©": f"üîç Points d'am√©lioration: Code review n√©cessaire, tests automatis√©s, s√©curit√© √† renforcer.",
            "Optimiseur de Code": f"‚ö° Optimisations: Performance am√©lior√©e, code refactoris√©, meilleures pratiques appliqu√©es.",
            "Traducteur": f"üåê Traduction: Adaptation multilingue avec contexte culturel et terminologie appropri√©e."
        }
        
        return fallbacks.get(self.role, f"{self.emoji} {self.name}: R√©ponse en cours de pr√©paration...")

# Orchestrateur am√©lior√©
class EnhancedOrchestrator:
    def __init__(self):
        self.agents = {}
        self.available_agents = {
            name: EnhancedAgent(name, config) 
            for name, config in AGENT_CONFIGS.items()
        }
        
    def get_agent_status(self) -> Dict[str, Dict]:
        """Retourne le statut de tous les agents"""
        status = {}
        for name, agent in self.available_agents.items():
            is_available = agent.check_model_availability()
            status[name] = {
                "available": is_available,
                "model": agent.model,
                "role": agent.role,
                "description": agent.description,
                "color": agent.color,
                "emoji": agent.emoji
            }
        return status
    
    def select_agents(self, agent_names: List[str]) -> List[EnhancedAgent]:
        """S√©lection d'agents avec validation"""
        selected = []
        for name in agent_names[:5]:  # Limite √† 5 agents
            if name in self.available_agents:
                selected.append(self.available_agents[name])
        return selected

# Workflow am√©lior√© avec WebSocket
async def enhanced_workflow_with_websocket(
    orchestrator: EnhancedOrchestrator, 
    user_input: str, 
    selected_agents: List[str],
    websocket: WebSocket,
    session_id: str
) -> Dict[str, Any]:
    """Workflow am√©lior√© avec communication WebSocket temps r√©el"""
    
    logger.info(f"üöÄ Workflow Enhanced d√©marr√© - Session: {session_id}")
    
    try:
        # S√©lection des agents
        agents = orchestrator.select_agents(selected_agents)
        
        if not agents:
            await websocket.send_text(json.dumps({
                "type": "error",
                "message": "‚ùå Aucun agent valide s√©lectionn√©"
            }))
            return {"error": "No valid agents selected"}
        
        # Envoi du message de d√©marrage
        await websocket.send_text(json.dumps({
            "type": "workflow_start",
            "message": f"üöÄ Workflow d√©marr√© avec {len(agents)} agents",
            "agents": [agent.name for agent in agents],
            "session_id": session_id
        }))
        
        results = {}
        context = {
            "session_id": session_id,
            "timestamp": datetime.now().isoformat(),
            "total_agents": len(agents)
        }
        
        for i, agent in enumerate(agents):
            stage = f"step_{i+1}"
            
            try:
                # Message de d√©but d'√©tape
                await websocket.send_text(json.dumps({
                    "type": "agent_message",
                    "agent": agent.name,
                    "status": f"√âtape {i+1}/{len(agents)} - En cours...",
                    "content": "üîÑ Analyse en cours...",
                    "stage": stage,
                    "timestamp": datetime.now().isoformat()
                }))
                
                start_time = time.time()
                
                # R√©flexion de l'agent
                thought = agent.think(context)
                
                # Action de l'agent (async)
                response = await agent.act_async(user_input, context)
                
                execution_time = time.time() - start_time
                
                # Stockage du r√©sultat
                results[agent.name] = {
                    "thought": thought,
                    "response": response,
                    "execution_time": execution_time,
                    "model": agent.model
                }
                
                # Envoi du r√©sultat via WebSocket
                await websocket.send_text(json.dumps({
                    "type": "agent_message", 
                    "agent": agent.name,
                    "status": "Termin√©",
                    "content": response,
                    "stage": stage,
                    "elapsed": execution_time,
                    "timestamp": datetime.now().isoformat()
                }))
                
                logger.info(f"‚úÖ {agent.name} termin√© en {execution_time:.2f}s")
                
                # Pause entre agents
                await asyncio.sleep(0.5)
                
            except Exception as e:
                execution_time = time.time() - start_time
                error_msg = f"‚ùå Erreur {agent.name}: {str(e)[:100]}"
                
                results[agent.name] = {
                    "thought": "Erreur de r√©flexion",
                    "response": error_msg,
                    "execution_time": execution_time,
                    "model": agent.model
                }
                
                await websocket.send_text(json.dumps({
                    "type": "agent_message",
                    "agent": agent.name,
                    "status": "Erreur",
                    "content": error_msg,
                    "stage": stage,
                    "elapsed": execution_time,
                    "timestamp": datetime.now().isoformat()
                }))
                
                logger.error(f"‚ùå Erreur {agent.name}: {e}")
                logger.error(f"Traceback: {traceback.format_exc()}")
        
        # Message de fin de workflow
        await websocket.send_text(json.dumps({
            "type": "workflow_complete",
            "message": "‚úÖ Workflow termin√© avec succ√®s !",
            "session_id": session_id,
            "results_count": len(results),
            "agents_executed": len(agents),
            "timestamp": datetime.now().isoformat()
        }))
        
        logger.info(f"üèÅ Workflow Enhanced termin√© - Session: {session_id}")
        return results
        
    except Exception as e:
        logger.error(f"üî• Erreur critique workflow - Session: {session_id} - {e}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        
        try:
            await websocket.send_text(json.dumps({
                "type": "workflow_error",
                "message": f"‚ùå Erreur critique workflow: {str(e)[:100]}",
                "session_id": session_id
            }))
        except:
            pass
        
        return {"error": str(e)}

# Instances globales
orchestrator = EnhancedOrchestrator()
connection_manager = ConnectionManager()

# Routes API
@app.get("/")
async def root():
    """Endpoint racine avec statut d√©taill√©"""
    try:
        agent_status = orchestrator.get_agent_status()
        available_count = sum(1 for status in agent_status.values() if status["available"])
        
        return {
            "message": "üöÄ Backend Stable Enhanced - Agents IA Ollama",
            "version": "2.0.1",
            "status": "running",
            "agents_available": f"{available_count}/{len(agent_status)}",
            "active_connections": len(connection_manager.active_connections),
            "ollama_connection": "‚úÖ Connect√©" if available_count > 0 else "‚ùå D√©connect√©",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Erreur endpoint root: {e}")
        return {
            "message": "‚ö†Ô∏è Backend en cours de d√©marrage",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/agents")
async def get_agents():
    """Liste des agents avec statut en temps r√©el"""
    try:
        agent_status = orchestrator.get_agent_status()
        
        return {
            "agents": [
                {
                    "id": name,
                    "name": name,
                    "role": status["role"],
                    "model": status["model"],
                    "description": status["description"],
                    "color": status["color"],
                    "emoji": status["emoji"],
                    "available": status["available"],
                    "status": "‚úÖ Pr√™t" if status["available"] else "‚ùå Mod√®le manquant"
                }
                for name, status in agent_status.items()
            ],
            "summary": {
                "total": len(agent_status),
                "available": sum(1 for s in agent_status.values() if s["available"]),
                "missing": sum(1 for s in agent_status.values() if not s["available"])
            }
        }
    except Exception as e:
        logger.error(f"Erreur get_agents: {e}")
        return {"error": str(e)}

@app.get("/models/check")
async def check_ollama_models():
    """V√©rifie les mod√®les Ollama disponibles"""
    try:
        models = ollama.list()
        available_models = [model['name'] for model in models.get('models', [])]
        
        required_models = list(set(config["model"] for config in AGENT_CONFIGS.values()))
        missing_models = [model for model in required_models if model not in available_models]
        
        return {
            "ollama_status": "‚úÖ Connect√©",
            "total_models": len(available_models),
            "available_models": available_models,
            "required_models": required_models,
            "missing_models": missing_models,
            "setup_commands": [f"ollama pull {model}" for model in missing_models] if missing_models else []
        }
    except Exception as e:
        logger.error(f"Erreur check_ollama_models: {e}")
        return {
            "ollama_status": "‚ùå D√©connect√©",
            "error": str(e),
            "suggestion": "D√©marrez Ollama avec: ollama serve"
        }

@app.get("/server/status")
async def server_status():
    """Statut d√©taill√© du serveur"""
    try:
        agent_status = orchestrator.get_agent_status()
        
        return {
            "status": "‚úÖ Op√©rationnel",
            "timestamp": datetime.now().isoformat(),
            "connections": {
                "active": len(connection_manager.active_connections),
                "max_allowed": connection_manager.max_connections
            },
            "agents": {
                "total": len(orchestrator.available_agents),
                "available": len([a for a in orchestrator.available_agents.values() if a.check_model_availability()])
            },
            "system": {
                "python_version": f"{__import__('sys').version_info.major}.{__import__('sys').version_info.minor}",
                "fastapi_version": "Latest"
            }
        }
    except Exception as e:
        logger.error(f"Erreur server_status: {e}")
        return {"error": str(e)}

@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """Endpoint WebSocket robuste et s√©curis√©"""
    
    # Validation du session_id
    if not session_id or len(session_id) < 3:
        await websocket.close(code=1008, reason="Session ID invalide")
        return
    
    # Connexion avec gestionnaire
    if not await connection_manager.connect(websocket, session_id):
        return
    
    try:
        # Message de connexion
        await websocket.send_text(json.dumps({
            "type": "connection_established",
            "message": "‚úÖ Connexion WebSocket √©tablie",
            "session_id": session_id,
            "timestamp": datetime.now().isoformat(),
            "server_info": {
                "version": "2.0.1",
                "active_connections": len(connection_manager.active_connections)
            }
        }))
        
        while True:
            try:
                # Timeout pour √©viter les connexions bloqu√©es
                data = await asyncio.wait_for(
                    websocket.receive_text(), 
                    timeout=300.0  # 5 minutes timeout
                )
                
                message_data = json.loads(data)
                
                # Validation du message
                if not isinstance(message_data, dict):
                    await websocket.send_text(json.dumps({
                        "type": "error",
                        "message": "‚ùå Format de message invalide"
                    }))
                    continue
                
                # Gestion des diff√©rents types de messages
                if message_data.get("type") == "chat_request":
                    prompt = message_data.get("prompt", "").strip()
                    selected_agents = message_data.get("selected_agents", [])
                    
                    # Validation des donn√©es
                    if not prompt:
                        await websocket.send_text(json.dumps({
                            "type": "error",
                            "message": "‚ùå Prompt vide"
                        }))
                        continue
                    
                    if not selected_agents:
                        await websocket.send_text(json.dumps({
                            "type": "error",
                            "message": "‚ùå Aucun agent s√©lectionn√©"
                        }))
                        continue
                    
                    # Limiter le nombre d'agents
                    if len(selected_agents) > 5:
                        selected_agents = selected_agents[:5]
                        await websocket.send_text(json.dumps({
                            "type": "warning",
                            "message": "‚ö†Ô∏è Limit√© √† 5 agents maximum"
                        }))
                    
                    # Ex√©cuter le workflow
                    await enhanced_workflow_with_websocket(
                        orchestrator, prompt, selected_agents, websocket, session_id
                    )
                
                elif message_data.get("type") == "ping":
                    # R√©pondre au ping du client
                    await websocket.send_text(json.dumps({
                        "type": "pong",
                        "timestamp": datetime.now().isoformat()
                    }))
                
                elif message_data.get("type") == "get_agents":
                    # Envoyer la liste des agents
                    agent_status = orchestrator.get_agent_status()
                    await websocket.send_text(json.dumps({
                        "type": "agents_list",
                        "agents": agent_status
                    }))
                
                else:
                    await websocket.send_text(json.dumps({
                        "type": "error",
                        "message": f"‚ùå Type de message non reconnu: {message_data.get('type')}"
                    }))
                
            except asyncio.TimeoutError:
                logger.warning(f"[{session_id}] Timeout - connexion ferm√©e")
                break
            except WebSocketDisconnect:
                logger.info(f"[{session_id}] Connexion ferm√©e par le client")
                break
            except json.JSONDecodeError:
                await websocket.send_text(json.dumps({
                    "type": "error",
                    "message": "‚ùå Format JSON invalide"
                }))
            except Exception as e:
                logger.error(f"[{session_id}] Erreur WebSocket: {e}")
                logger.error(f"Traceback: {traceback.format_exc()}")
                await websocket.send_text(json.dumps({
                    "type": "error", 
                    "message": f"‚ùå Erreur: {str(e)}"
                }))
                
    except Exception as e:
        logger.error(f"[{session_id}] Erreur critique WebSocket: {e}")
        logger.error(f"Traceback: {traceback.format_exc()}")
    finally:
        # Nettoyage
        await connection_manager.disconnect(session_id)

@app.post("/chat")
async def chat_with_agent(request: ChatRequest):
    """Chat direct avec un agent"""
    try:
        if request.agent_name not in orchestrator.available_agents:
            raise HTTPException(status_code=404, detail="Agent non trouv√©")
            
        agent = orchestrator.available_agents[request.agent_name]
        start_time = time.time()
        
        response = agent.act(request.message, request.context or {})
        execution_time = time.time() - start_time
        
        return AgentResponse(
            agent=agent.name,
            response=response,
            model=agent.model,
            execution_time=execution_time,
            timestamp=datetime.now()
        )
    except Exception as e:
        logger.error(f"Erreur chat_with_agent: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/workflow")
async def run_stable_workflow(request: WorkflowRequest):
    """Workflow HTTP (version simplifi√©e)"""
    try:
        if request.agent_names:
            agents = orchestrator.select_agents(request.agent_names)
        else:
            agents = orchestrator.select_agents(["Mike", "Bob", "FrontEngineer"])
        
        context = {
            "timestamp": datetime.now().isoformat(),
            "user_input_length": len(request.user_input)
        }
        
        results = {}
        for agent in agents:
            try:
                start_time = time.time()
                thought = agent.think(context)
                response = agent.act(request.user_input, context)
                execution_time = time.time() - start_time
                
                results[agent.name] = {
                    "thought": thought,
                    "response": response,
                    "execution_time": execution_time,
                    "model": agent.model
                }
            except Exception as e:
                logger.error(f"Erreur agent {agent.name}: {e}")
                results[agent.name] = {
                    "thought": "Erreur",
                    "response": f"Erreur: {str(e)}",
                    "execution_time": 0,
                    "model": agent.model
                }
        
        return {
            "status": "success",
            "user_input": request.user_input,
            "agents_used": [agent.name for agent in agents],
            "results": results,
            "execution_timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Erreur run_stable_workflow: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/test")
async def test_endpoint():
    """Test de connectivit√©"""
    return {
        "status": "‚úÖ Backend op√©rationnel",
        "timestamp": datetime.now().isoformat(),
        "port": 8002,
        "version": "2.0.1"
    }

@app.post("/admin/close-session/{session_id}")
async def force_close_session(session_id: str):
    """Force la fermeture d'une session WebSocket"""
    try:
        if session_id in connection_manager.active_connections:
            websocket = connection_manager.active_connections[session_id]
            await websocket.close(code=1000, reason="Session ferm√©e par l'administrateur")
            await connection_manager.disconnect(session_id)
            return {"message": f"Session {session_id} ferm√©e"}
        return {"error": "Session non trouv√©e"}
    except Exception as e:
        logger.error(f"Erreur force_close_session: {e}")
        return {"error": str(e)}

@app.on_event("startup")
async def startup_event():
    """√âv√©nement de d√©marrage"""
    logger.info("üöÄ Backend Enhanced d√©marr√©")
    logger.info(f"üì° WebSocket disponible sur: ws://localhost:8002/ws/{{session_id}}")
    logger.info(f"üîó API documentation: http://localhost:8002/docs")
    
    # V√©rifier Ollama au d√©marrage
    try:
        models = ollama.list()
        logger.info(f"‚úÖ Ollama connect√© - {len(models.get('models', []))} mod√®les disponibles")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Ollama non disponible: {e}")

@app.on_event("shutdown") 
async def shutdown_event():
    """√âv√©nement de fermeture"""
    logger.info("üõë Fermeture du backend...")
    
    # Fermer toutes les connexions WebSocket
    for session_id in list(connection_manager.active_connections.keys()):
        try:
            websocket = connection_manager.active_connections[session_id]
            await websocket.close(code=1001, reason="Serveur en cours de fermeture")
            await connection_manager.disconnect(session_id)
        except Exception:
            pass
    
    logger.info("‚úÖ Backend ferm√© proprement")

if __name__ == "__main__":
    import uvicorn
    
    # Configuration de production
    config = {
        "app": app,
        "host": "0.0.0.0",
        "port": 8002,
        "reload": False,
        "log_level": "info",
        "access_log": True,
        "ws_ping_interval": 20,  # Ping WebSocket toutes les 20 secondes
        "ws_ping_timeout": 10,   # Timeout ping √† 10 secondes
        "workers": 1,  # Important pour WebSocket
        "loop": "asyncio"
    }
    
    logger.info("üöÄ D√©marrage du serveur Backend Enhanced")
    logger.info(f"üì° WebSocket disponible sur: ws://localhost:8002/ws/{{session_id}}")
    logger.info(f"üîó API documentation: http://localhost:8002/docs")
    
    uvicorn.run(**config)

# Ajoutez ces corrections √† votre backend_stable_enhanced.py

# 1. CORRECTION: Configuration des agents pour correspondre au frontend
AGENT_CONFIGS = {
    "Mike": {
        "model": "agent-visionnaire",
        "role": "Team Leader / Visionnaire",
        "description": "Coordinateur de projet et d√©finition de vision",
        "color": "#6366F1",
        "emoji": "üîÆ"
    },
    "Bob": {
        "model": "agent-architecte", 
        "role": "Architecte Logiciel",
        "description": "Expert en architecture technique",
        "color": "#3B82F6",
        "emoji": "üèóÔ∏è"
    },
    "FrontEngineer": {
        "model": "agent-frontend-engineer",
        "role": "Ing√©nieur Frontend", 
        "description": "D√©veloppeur React/JavaScript",
        "color": "#F59E0B",
        "emoji": "üé®"
    },
    "BackEngineer": {
        "model": "agent-backend-engineer",
        "role": "Ing√©nieur Backend",
        "description": "D√©veloppeur FastAPI/Python",
        "color": "#10B981", 
        "emoji": "‚öôÔ∏è"
    },
    "UIDesigner": {
        "model": "agent-designer-ui-ux",
        "role": "Designer UI/UX",
        "description": "Expert en design d'interface",
        "color": "#8B5CF6",
        "emoji": "‚ú®"
    },
    "SEOCopty": {
        "model": "agent-seo-content-expert",
        "role": "Expert SEO/Contenu",
        "description": "Sp√©cialiste SEO et contenu",
        "color": "#059669",
        "emoji": "üìà"
    },
    "DBMaster": {
        "model": "agent-database-specialist",
        "role": "Sp√©cialiste Base de Donn√©es", 
        "description": "Expert en bases de donn√©es",
        "color": "#EF4444",
        "emoji": "üóÉÔ∏è"
    },
    "DevOpsGuy": {
        "model": "agent-deployer-devops",
        "role": "Expert DevOps",
        "description": "Sp√©cialiste d√©ploiement",
        "color": "#06B6D4",
        "emoji": "üöÄ"
    },
    "TheCritique": {
        "model": "agent-critique",
        "role": "Critique Qualit√©",
        "description": "Expert en qualit√© et s√©curit√©",
        "color": "#F97316", 
        "emoji": "üîç"
    },
    "TheOptimizer": {
        "model": "agent-optimiseur",
        "role": "Optimiseur de Code",
        "description": "Expert en optimisation",
        "color": "#84CC16",
        "emoji": "‚ö°"
    },
    "TranslatorBot": {
        "model": "agent-translator",
        "role": "Traducteur",
        "description": "Expert en traduction",
        "color": "#0EA5E9",
        "emoji": "üåç"
    }
}

# 2. CORRECTION: Classe EnhancedAgent modifi√©e
class EnhancedAgent:
    def __init__(self, name: str, config: dict):
        self.name = name
        self.id = name  # AJOUT: ID identique au nom pour correspondance frontend
        self.model = config["model"]
        self.role = config["role"]
        self.description = config["description"]
        self.color = config["color"]
        self.emoji = config["emoji"]
        self._model_available = None
        self._last_check = 0
        
    def check_model_availability(self) -> bool:
        """V√©rifie si le mod√®le Ollama est disponible avec cache"""
        current_time = time.time()
        
        # Cache la v√©rification pendant 60 secondes
        if self._model_available is not None and (current_time - self._last_check) < 60:
            return self._model_available
        
        try:
            models = ollama.list()
            available_models = [model['name'] for model in models.get('models', [])]
            self._model_available = self.model in available_models
            self._last_check = current_time
            
            # Log pour debug
            if not self._model_available:
                logger.warning(f"Mod√®le {self.model} non trouv√©. Mod√®les disponibles: {available_models}")
            
            return self._model_available
        except Exception as e:
            logger.error(f"Erreur v√©rification mod√®le {self.model}: {e}")
            self._model_available = False
            return False

# 3. CORRECTION: Orchestrateur modifi√©
class EnhancedOrchestrator:
    def __init__(self):
        self.agents = {}
        self.available_agents = {
            name: EnhancedAgent(name, config) 
            for name, config in AGENT_CONFIGS.items()
        }
        
        # Log des agents cr√©√©s
        logger.info(f"Orchestrateur initialis√© avec {len(self.available_agents)} agents:")
        for name, agent in self.available_agents.items():
            logger.info(f"  - {name} ({agent.model}) - {'‚úÖ' if agent.check_model_availability() else '‚ùå'}")
        
    def get_agent_status(self) -> Dict[str, Dict]:
        """Retourne le statut de tous les agents"""
        status = {}
        for name, agent in self.available_agents.items():
            try:
                is_available = agent.check_model_availability()
                status[name] = {
                    "id": agent.id,
                    "name": agent.name,
                    "available": is_available,
                    "model": agent.model,
                    "role": agent.role,
                    "description": agent.description,
                    "color": agent.color,
                    "emoji": agent.emoji,
                    "status": "‚úÖ Pr√™t" if is_available else f"‚ùå Mod√®le {agent.model} manquant"
                }
            except Exception as e:
                logger.error(f"Erreur lors de la v√©rification de l'agent {name}: {e}")
                status[name] = {
                    "id": name,
                    "name": name,
                    "available": False,
                    "model": "unknown",
                    "role": "unknown",
                    "description": "Erreur de configuration",
                    "color": "#666666",
                    "emoji": "‚ùå",
                    "status": f"‚ùå Erreur: {str(e)}"
                }
        return status

# 4. CORRECTION: Route /chat modifi√©e pour g√©rer les agents par ID
@app.post("/chat")
async def chat_with_agent(request: ChatRequest):
    """Chat direct avec un agent"""
    try:
        # CORRECTION: Utiliser l'ID exact pour trouver l'agent
        agent_id = request.agent_name
        
        if agent_id not in orchestrator.available_agents:
            available_agents = list(orchestrator.available_agents.keys())
            logger.error(f"Agent '{agent_id}' non trouv√©. Agents disponibles: {available_agents}")
            raise HTTPException(
                status_code=404, 
                detail=f"Agent '{agent_id}' non trouv√©. Agents disponibles: {available_agents}"
            )
            
        agent = orchestrator.available_agents[agent_id]
        
        # V√©rifier que le mod√®le est disponible
        if not agent.check_model_availability():
            raise HTTPException(
                status_code=503, 
                detail=f"Mod√®le {agent.model} non disponible. Installez-le avec: ollama pull {agent.model}"
            )
        
        start_time = time.time()
        
        # CORRECTION: Utiliser act_async avec gestion d'erreur
        try:
            response = await agent.act_async(request.message, request.context or {})
        except Exception as e:
            logger.error(f"Erreur lors de l'ex√©cution de l'agent {agent_id}: {e}")
            response = agent._generate_fallback_response(request.message)
        
        execution_time = time.time() - start_time
        
        # CORRECTION: Structure de r√©ponse attendue par le frontend
        return {
            "agent": agent.name,
            "response": response,
            "model": agent.model,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat(),
            "success": True
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur inattendue dans chat_with_agent: {e}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")

# 5. CORRECTION: Route /test am√©lior√©e
@app.get("/test")
async def test_endpoint():
    """Endpoint de test avec informations d√©taill√©es"""
    try:
        # Test de connexion Ollama
        try:
            ollama_models = ollama.list()
            ollama_status = "‚úÖ Connect√©"
            models_count = len(ollama_models.get('models', []))
        except Exception as e:
            ollama_status = f"‚ùå Erreur: {str(e)}"
            models_count = 0
        
        # Statut des agents
        agent_status = orchestrator.get_agent_status()
        available_agents = sum(1 for status in agent_status.values() if status["available"])
        
        return {
            "status": "‚úÖ Backend op√©rationnel",
            "timestamp": datetime.now().isoformat(),
            "port": 8002,
            "version": "2.0.1",
            "ollama": {
                "status": ollama_status,
                "models_count": models_count
            },
            "agents": {
                "total": len(agent_status),
                "available": available_agents,
                "missing": len(agent_status) - available_agents
            },
            "endpoints": {
                "api_docs": "http://localhost:8002/docs",
                "agents_list": "http://localhost:8002/agents",
                "websocket": "ws://localhost:8002/ws/{session_id}"
            }
        }
    except Exception as e:
        logger.error(f"Erreur dans test_endpoint: {e}")
        return {
            "status": "‚ö†Ô∏è Backend partiellement op√©rationnel",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# 6. CORRECTION: Endpoint pour installer un mod√®le manquant
@app.post("/admin/install-model/{model_name}")
async def install_model(model_name: str):
    """Installe un mod√®le Ollama manquant"""
    try:
        import subprocess
        
        logger.info(f"Installation du mod√®le {model_name}...")
        
        # Ex√©cuter ollama pull en arri√®re-plan
        process = subprocess.Popen(
            ["ollama", "pull", model_name],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # Attendre un peu pour voir si la commande d√©marre
        try:
            stdout, stderr = process.communicate(timeout=5)
            if process.returncode == 0:
                return {"success": True, "message": f"Mod√®le {model_name} install√© avec succ√®s"}
            else:
                return {"success": False, "error": stderr}
        except subprocess.TimeoutExpired:
            # La commande prend du temps, c'est normal
            return {"success": True, "message": f"Installation de {model_name} en cours..."}
            
    except Exception as e:
        logger.error(f"Erreur lors de l'installation du mod√®le {model_name}: {e}")
        return {"success": False, "error": str(e)}

# 7. CORRECTION: Logs am√©lior√©s au d√©marrage
@app.on_event("startup")
async def startup_event():
    """√âv√©nement de d√©marrage avec v√©rifications"""
    logger.info("üöÄ Backend Enhanced d√©marr√©")
    logger.info(f"üì° WebSocket disponible sur: ws://localhost:8002/ws/{{session_id}}")
    logger.info(f"üîó API documentation: http://localhost:8002/docs")
    
    # V√©rifier Ollama au d√©marrage
    try:
        models = ollama.list()
        available_models = [model['name'] for model in models.get('models', [])]
        logger.info(f"‚úÖ Ollama connect√© - {len(available_models)} mod√®les disponibles")
        
        # V√©rifier chaque mod√®le requis
        required_models = list(set(config["model"] for config in AGENT_CONFIGS.values()))
        missing_models = [model for model in required_models if model not in available_models]
        
        if missing_models:
            logger.warning(f"‚ö†Ô∏è Mod√®les manquants: {missing_models}")
            logger.info("üí° Pour installer les mod√®les manquants:")
            for model in missing_models:
                logger.info(f"   ollama pull {model}")
        else:
            logger.info("üéâ Tous les mod√®les requis sont install√©s!")
            
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Ollama non disponible: {e}")
        logger.info("üí° D√©marrez Ollama avec: ollama serve")
    
    # Statut des agents
    agent_status = orchestrator.get_agent_status()
    available_count = sum(1 for status in agent_status.values() if status["available"])
    logger.info(f"ü§ñ Agents: {available_count}/{len(agent_status)} disponibles")
    
    for name, status in agent_status.items():
        if status["available"]:
            logger.info(f"   ‚úÖ {status['emoji']} {name} ({status['model']})")
        else:
            logger.warning(f"   ‚ùå {status['emoji']} {name} ({status['model']}) - {status['status']}")

# 8. CORRECTION: Gestion d'erreur am√©lior√©e pour le WebSocket
@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """Endpoint WebSocket robuste et s√©curis√©"""
    
    # Validation du session_id
    if not session_id or len(session_id) < 3:
        await websocket.close(code=1008, reason="Session ID invalide")
        return
    
    # Connexion avec gestionnaire
    if not await connection_manager.connect(websocket, session_id):
        return
    
    try:
        # Message de connexion avec statut des agents
        agent_status = orchestrator.get_agent_status()
        available_agents = sum(1 for status in agent_status.values() if status["available"])
        
        await websocket.send_text(json.dumps({
            "type": "connection_established",
            "message": "‚úÖ Connexion WebSocket √©tablie",
            "session_id": session_id,
            "timestamp": datetime.now().isoformat(),
            "server_info": {
                "version": "2.0.1",
                "active_connections": len(connection_manager.active_connections),
                "agents_available": f"{available_agents}/{len(agent_status)}"
            }
        }))
        
        while True:
            try:
                # Timeout pour √©viter les connexions bloqu√©es
                data = await asyncio.wait_for(
                    websocket.receive_text(), 
                    timeout=300.0  # 5 minutes timeout
                )
                
                message_data = json.loads(data)
                
                # Log de debug
                logger.debug(f"[{session_id}] Message re√ßu: {message_data.get('type')}")
                
                # Validation du message
                if not isinstance(message_data, dict):
                    await websocket.send_text(json.dumps({
                        "type": "error",
                        "message": "‚ùå Format de message invalide"
                    }))
                    continue
                
                # Gestion des diff√©rents types de messages
                if message_data.get("type") == "chat_request":
                    prompt = message_data.get("prompt", "").strip()
                    selected_agents = message_data.get("selected_agents", [])
                    
                    # Validation des donn√©es
                    if not prompt:
                        await websocket.send_text(json.dumps({
                            "type": "error",
                            "message": "‚ùå Prompt vide"
                        }))
                        continue
                    
                    if not selected_agents:
                        # Utiliser des agents par d√©faut
                        selected_agents = ["Mike", "Bob", "FrontEngineer"]
                        await websocket.send_text(json.dumps({
                            "type": "info",
                            "message": f"‚ÑπÔ∏è Agents par d√©faut s√©lectionn√©s: {', '.join(selected_agents)}"
                        }))
                    
                    # Limiter le nombre d'agents
                    if len(selected_agents) > 5:
                        selected_agents = selected_agents[:5]
                        await websocket.send_text(json.dumps({
                            "type": "warning",
                            "message": "‚ö†Ô∏è Limit√© √† 5 agents maximum"
                        }))
                    
                    # V√©rifier que les agents existent
                    valid_agents = []
                    for agent_id in selected_agents:
                        if agent_id in orchestrator.available_agents:
                            valid_agents.append(agent_id)
                        else:
                            logger.warning(f"Agent {agent_id} non trouv√©")
                    
                    if not valid_agents:
                        await websocket.send_text(json.dumps({
                            "type": "error",
                            "message": "‚ùå Aucun agent valide s√©lectionn√©"
                        }))
                        continue
                    
                    # Ex√©cuter le workflow
                    try:
                        await enhanced_workflow_with_websocket(
                            orchestrator, prompt, valid_agents, websocket, session_id
                        )
                    except Exception as workflow_error:
                        logger.error(f"[{session_id}] Erreur workflow: {workflow_error}")
                        await websocket.send_text(json.dumps({
                            "type": "workflow_error",
                            "message": f"‚ùå Erreur workflow: {str(workflow_error)}"
                        }))
                
                elif message_data.get("type") == "ping":
                    # R√©pondre au ping du client
                    await websocket.send_text(json.dumps({
                        "type": "pong",
                        "timestamp": datetime.now().isoformat()
                    }))
                
                elif message_data.get("type") == "get_agents":
                    # Envoyer la liste des agents
                    agent_status = orchestrator.get_agent_status()
                    await websocket.send_text(json.dumps({
                        "type": "agents_list",
                        "agents": agent_status
                    }))
                
                else:
                    await websocket.send_text(json.dumps({
                        "type": "error",
                        "message": f"‚ùå Type de message non reconnu: {message_data.get('type')}"
                    }))
                
            except asyncio.TimeoutError:
                logger.warning(f"[{session_id}] Timeout - connexion ferm√©e")
                break
            except WebSocketDisconnect:
                logger.info(f"[{session_id}] Connexion ferm√©e par le client")
                break
            except json.JSONDecodeError:
                await websocket.send_text(json.dumps({
                    "type": "error",
                    "message": "‚ùå Format JSON invalide"
                }))
            except Exception as e:
                logger.error(f"[{session_id}] Erreur WebSocket: {e}")
                await websocket.send_text(json.dumps({
                    "type": "error", 
                    "message": f"‚ùå Erreur: {str(e)}"
                }))
                
    except Exception as e:
        logger.error(f"[{session_id}] Erreur critique WebSocket: {e}")
        logger.error(f"Traceback: {traceback.format_exc()}")
    finally:
        # Nettoyage
        await connection_manager.disconnect(session_id)

# 9. CORRECTION: Configuration CORS √©largie
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "http://127.0.0.1:5173",
        "http://localhost:3000",
        "http://localhost:3001", 
        "http://127.0.0.1:3000",
        "http://127.0.0.1:3001",
        "http://localhost:4173",  # Vite preview
        "http://127.0.0.1:4173"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# 10. CORRECTION: Endpoint de debug pour les d√©veloppeurs
@app.get("/debug/agents")
async def debug_agents():
    """Endpoint de debug pour v√©rifier l'√©tat des agents"""
    try:
        # Informations d√©taill√©es sur chaque agent
        agents_debug = {}
        
        for name, agent in orchestrator.available_agents.items():
            try:
                # Test de disponibilit√© du mod√®le
                model_available = agent.check_model_availability()
                
                # Test de g√©n√©ration simple
                test_response = "Non test√©"
                if model_available:
                    try:
                        test_response = await agent.act_async("Dis simplement 'Je fonctionne correctement'", {})
                        test_response = test_response[:100] + "..." if len(test_response) > 100 else test_response
                    except Exception as test_error:
                        test_response = f"Erreur test: {str(test_error)}"
                
                agents_debug[name] = {
                    "id": agent.id,
                    "model": agent.model,
                    "role": agent.role,
                    "model_available": model_available,
                    "test_response": test_response,
                    "last_check": agent._last_check,
                    "config": {
                        "emoji": agent.emoji,
                        "color": agent.color,
                        "description": agent.description
                    }
                }
            except Exception as agent_error:
                agents_debug[name] = {
                    "error": str(agent_error),
                    "model": getattr(agent, 'model', 'unknown')
                }
        
        # Informations Ollama
        try:
            ollama_models = ollama.list()
            ollama_info = {
                "status": "available",
                "models": [model['name'] for model in ollama_models.get('models', [])]
            }
        except Exception as e:
            ollama_info = {
                "status": "error",
                "error": str(e)
            }
        
        return {
            "agents": agents_debug,
            "ollama": ollama_info,
            "server": {
                "timestamp": datetime.now().isoformat(),
                "active_connections": len(connection_manager.active_connections)
            }
        }
    except Exception as e:
        logger.error(f"Erreur debug_agents: {e}")
        return {"error": str(e)}

# 11. CORRECTION: Configuration du port explicite
if __name__ == "__main__":
    import uvicorn
    
    # Configuration de production avec port explicite
    config = {
        "app": app,
        "host": "0.0.0.0",
        "port": 8002,  # IMPORTANT: Port 8002 explicite
        "reload": False,
        "log_level": "info",
        "access_log": True,
        "ws_ping_interval": 20,
        "ws_ping_timeout": 10,
        "workers": 1,
        "loop": "asyncio"
    }
    
    logger.info("üöÄ D√©marrage du serveur Backend Enhanced")
    logger.info(f"üì° API disponible sur: http://localhost:8002")
    logger.info(f"üì° WebSocket disponible sur: ws://localhost:8002/ws/{{session_id}}")
    logger.info(f"üîó Documentation API: http://localhost:8002/docs")
    logger.info(f"üîß Debug agents: http://localhost:8002/debug/agents")
    
# Dans backend-python/backend_stable_enhanced.py
# LIGNE FINALE, remplacer:
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)  # ‚Üê Changer 8002 ‚Üí 8000

# start_agents.py - Script de lancement complet
import os
import sys
import subprocess
import time
import requests
import ollama
from pathlib import Path

def check_ollama_status():
    """VÃ©rifie si Ollama est dÃ©marrÃ©"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        return response.status_code == 200
    except:
        return False

def check_required_models():
    """VÃ©rifie les modÃ¨les requis"""
    required_models = [
        "agent-visionnaire",
        "agent-architecte", 
        "agent-frontend-engineer",
        "agent-backend-engineer",
        "agent-designer-ui-ux",
        "agent-seo-content-expert",
        "agent-database-specialist",
        "agent-deployer-devops",
        "agent-critique",
        "agent-optimiseur",
        "agent-translator"
    ]
    
    try:
        models = ollama.list()
        available_models = [model['name'] for model in models.get('models', [])]
        missing_models = [model for model in required_models if model not in available_models]
        return available_models, missing_models
    except:
        return [], required_models

def install_missing_models(missing_models):
    """Installe les modÃ¨les manquants"""
    print(f"ğŸ“¦ Installation de {len(missing_models)} modÃ¨les manquants...")
    
    for model in missing_models:
        print(f"â¬‡ï¸ Installation de {model}...")
        try:
            # Commande d'installation via subprocess
            result = subprocess.run(
                ["ollama", "pull", model], 
                capture_output=True, 
                text=True,
                timeout=300  # 5 minutes max par modÃ¨le
            )
            
            if result.returncode == 0:
                print(f"âœ… {model} installÃ© avec succÃ¨s")
            else:
                print(f"âŒ Erreur installation {model}: {result.stderr}")
        except subprocess.TimeoutExpired:
            print(f"â° Timeout lors de l'installation de {model}")
        except Exception as e:
            print(f"âŒ Erreur {model}: {e}")

def start_ollama():
    """DÃ©marre Ollama si nÃ©cessaire"""
    if not check_ollama_status():
        print("ğŸ”„ DÃ©marrage d'Ollama...")
        try:
            # DÃ©marrage d'Ollama en arriÃ¨re-plan
            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            
            # Attente du dÃ©marrage
            for i in range(30):  # 30 secondes max
                if check_ollama_status():
                    print("âœ… Ollama dÃ©marrÃ© avec succÃ¨s")
                    return True
                time.sleep(1)
                print(f"â³ Attente Ollama... ({i+1}/30)")
            
            print("âŒ Timeout - Ollama n'a pas dÃ©marrÃ©")
            return False
        except Exception as e:
            print(f"âŒ Erreur dÃ©marrage Ollama: {e}")
            return False
    else:
        print("âœ… Ollama dÃ©jÃ  dÃ©marrÃ©")
        return True

def start_backend():
    """DÃ©marre le backend FastAPI"""
    print("ğŸš€ DÃ©marrage du backend...")
    
    # VÃ©rification du fichier backend
    backend_file = "backend_stable_enhanced.py"
    if not os.path.exists(backend_file):
        print(f"âŒ Fichier {backend_file} non trouvÃ©")
        return False
    
    try:
        # DÃ©marrage du backend
        subprocess.run([
            sys.executable, backend_file
        ], check=True)
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ Erreur dÃ©marrage backend: {e}")
        return False
    except KeyboardInterrupt:
        print("\nğŸ›‘ ArrÃªt demandÃ© par l'utilisateur")
        return False

def check_backend_health():
    """VÃ©rifie la santÃ© du backend"""
    try:
        response = requests.get("http://localhost:8002/test", timeout=5)
        return response.status_code == 200
    except:
        return False

def main():
    """Fonction principale"""
    print("ğŸ¤– === DÃ‰MARRAGE AGENTS IA OLLAMA ===\n")
    
    # 1. VÃ©rification et dÃ©marrage d'Ollama
    if not start_ollama():
        print("âŒ Impossible de dÃ©marrer Ollama")
        return
    
    # 2. VÃ©rification des modÃ¨les
    print("\nğŸ“‹ VÃ©rification des modÃ¨les...")
    available_models, missing_models = check_required_models()
    
    print(f"âœ… ModÃ¨les disponibles: {len(available_models)}")
    if available_models:
        for model in available_models[:5]:  # Affiche les 5 premiers
            print(f"   â€¢ {model}")
        if len(available_models) > 5:
            print(f"   â€¢ ... et {len(available_models) - 5} autres")
    
    if missing_models:
        print(f"\nâŒ ModÃ¨les manquants: {len(missing_models)}")
        for model in missing_models:
            print(f"   â€¢ {model}")
        
        response = input("\nğŸ“¦ Installer les modÃ¨les manquants ? (o/N): ")
        if response.lower() in ['o', 'oui', 'y', 'yes']:
            install_missing_models(missing_models)
        else:
            print("âš ï¸ Certains agents ne seront pas disponibles")
    
    # 3. DÃ©marrage du backend
    print(f"\nğŸš€ DÃ©marrage du backend sur le port 8002...")
    print("ğŸ“± Interface React disponible via WebSocket")
    print("ğŸ”— API: http://localhost:8002")
    print("ğŸ“Š Status: http://localhost:8002/agents")
    print("\nâ¹ï¸ Appuyez sur Ctrl+C pour arrÃªter\n")
    
    # DÃ©marrage du backend
    start_backend()

if __name__ == "__main__":
    main()